{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BHS Data Consolidation\n",
    "\n",
    "**Author:** CFOLKERS <br>\n",
    "**Ministry, Division, Branch:** WLRS, GeoBC, Geospatial Services <br>\n",
    "**Created Date:** 2023 12 14 <br>\n",
    "**Updated Date:**  2024 01 10 <br>\n",
    "**Description:** A tool to consolidate BHS data for the KB region and update the original dataset <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlalchemy \n",
    "import cx_Oracle\n",
    "from getpass import getpass\n",
    "from osgeo import ogr\n",
    "from osgeo import gdal\n",
    "import pandas\n",
    "import arcpy\n",
    "import os\n",
    "import openpyxl as pyxl\n",
    "from datetime import date\n",
    "\n",
    "#get oracle username and password \n",
    "username= input('Enter BCGW user name: ')\n",
    "password =getpass(prompt='Enter BCGW password: ')\n",
    "\n",
    "#gdbs\n",
    "exsitng_gdb=r'BHS_Data.gdb'\n",
    "temp_gdb=r'T:\\BHS_Temp.gdb'\n",
    "\n",
    "#XLSL tracking sheet\n",
    "tracker=r'BHS_Consolidated_Dataset_Tracking.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-10 09:01:42,469 INFO sqlalchemy.engine.Engine select sys_context( 'userenv', 'current_schema' ) from dual\n",
      "2024-01-10 09:01:42,470 INFO sqlalchemy.engine.Engine [raw sql] {}\n",
      "2024-01-10 09:01:42,547 INFO sqlalchemy.engine.Engine select value from nls_session_parameters where parameter = 'NLS_NUMERIC_CHARACTERS'\n",
      "2024-01-10 09:01:42,549 INFO sqlalchemy.engine.Engine [raw sql] {}\n"
     ]
    }
   ],
   "source": [
    "#create oracle connection and engine\n",
    "dialect=''\n",
    "sql_driver=''\n",
    "hostname=''\n",
    "port= 1\n",
    "service_name=''\n",
    "\n",
    "#  Connection string\n",
    "oracle_connection_string_fmt = (\n",
    "    'oracle+cx_oracle://{username}:{password}@' +\n",
    "    cx_Oracle.makedsn('{hostname}', '{port}', service_name='{service_name}')\n",
    ")\n",
    "url = oracle_connection_string_fmt.format(\n",
    "    username=username, password=password, \n",
    "    hostname=hostname, port=port, \n",
    "    service_name=service_name,\n",
    ")\n",
    "\n",
    "engine: sqlalchemy.engine.Engine = sqlalchemy.create_engine(url, echo=True)\n",
    "conn = engine.connect()\n",
    "metadata=sqlalchemy.MetaData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#query observation data set in bounding box (Kootenay Boundary)\n",
    "sql_obvs=\"\"\"\n",
    "select \n",
    "  b.SURVEY_OBSERVATION_ID as Observation_ID,\n",
    "  b.Species_Code,\n",
    "  b.ANIMAL_ID,\n",
    "  b.SEX,\n",
    "  b.OBSERVED_NUMBER,\n",
    "  b.OBSERVATION_DATETIME as Date_Time,\n",
    "  b.OBSERVATION_YEAR as Year,\n",
    "  b.OBSERVATION_MONTH as Month,\n",
    "  b.OBSERVATION_DAY as Day,\n",
    "  b.INVENTORY_METHOD,\n",
    "  b.UTM_SOURCE,\n",
    "  b.UTM_ZONE,\n",
    "  b.UTM_EASTING,\n",
    "  b.UTM_Northing,\n",
    "  b.PROJECT_NAME,\n",
    "  b.PROJECT_ID,\n",
    "  b.SURVEY_NAME,\n",
    "  b.SURVEY_ID,\n",
    "  SDO_UTIL.TO_WKTGEOMETRY(b.GEOMETRY)AS WKT_GEOMETRY\n",
    "from\n",
    "  WHSE_WILDLIFE_INVENTORY.SPI_SURVEY_OBS_ALL_SP b\n",
    "  \n",
    "where b.species_code = 'M-OVCA'\n",
    "\n",
    "and \n",
    "\n",
    "SDO_ANYINTERACT (GEOMETRY,\n",
    "\tSDO_GEOMETRY(2003, 3005, NULL,\n",
    "\t\tSDO_ELEM_INFO_ARRAY(1,1003,3),\n",
    "\t\tSDO_ORDINATE_ARRAY(1493647.6,466354.8,1889017.9,862609.6) \n",
    "\t)\n",
    ") = 'TRUE'\n",
    "  \n",
    "\"\"\"\n",
    "#query telemetry data set in bounding box (kootenay boundary)\n",
    "sql_tele=\"\"\"\n",
    "select \n",
    "  b.SURVEY_OBSERVATION_ID as Observation_ID,\n",
    "  b.Species_Code,\n",
    "  b.ANIMAL_ID,\n",
    "  b.SEX,\n",
    "  b.OBSERVED_NUMBER,\n",
    "  b.OBSERVATION_DATETIME as Date_Time,\n",
    "  b.OBSERVATION_YEAR as Year,\n",
    "  b.OBSERVATION_MONTH as Month,\n",
    "  b.OBSERVATION_DAY as Day,\n",
    "  b.UTM_ZONE,\n",
    "  b.UTM_EASTING,\n",
    "  b.UTM_Northing,\n",
    "  b.PROJECT_NAME,\n",
    "  b.PROJECT_ID,\n",
    "  b.SURVEY_NAME,\n",
    "  b.SURVEY_ID,\n",
    "  SDO_UTIL.TO_WKTGEOMETRY(b.GEOMETRY)AS WKT_GEOMETRY\n",
    "from\n",
    "  WHSE_WILDLIFE_INVENTORY.SPI_TELEMETRY_OBS_ALL_SP b\n",
    "  \n",
    "where b.species_code = 'M-OVCA'\n",
    "\n",
    "and \n",
    "\n",
    "SDO_ANYINTERACT (GEOMETRY,\n",
    "\tSDO_GEOMETRY(2003, 3005, NULL,\n",
    "\t\tSDO_ELEM_INFO_ARRAY(1,1003,3),\n",
    "\t\tSDO_ORDINATE_ARRAY(1493647.6,466354.8,1889017.9,862609.6) \n",
    "\t)\n",
    ") = 'TRUE'\n",
    "  \n",
    "\"\"\"\n",
    "# b.INVENTORY_METHOD\n",
    "  # b.UTM_SOURCE,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-10 09:02:03,777 INFO sqlalchemy.engine.Engine \n",
      "select \n",
      "  b.SURVEY_OBSERVATION_ID as Observation_ID,\n",
      "  b.Species_Code,\n",
      "  b.ANIMAL_ID,\n",
      "  b.SEX,\n",
      "  b.OBSERVED_NUMBER,\n",
      "  b.OBSERVATION_DATETIME as Date_Time,\n",
      "  b.OBSERVATION_YEAR as Year,\n",
      "  b.OBSERVATION_MONTH as Month,\n",
      "  b.OBSERVATION_DAY as Day,\n",
      "  b.INVENTORY_METHOD,\n",
      "  b.UTM_SOURCE,\n",
      "  b.UTM_ZONE,\n",
      "  b.UTM_EASTING,\n",
      "  b.UTM_Northing,\n",
      "  b.PROJECT_NAME,\n",
      "  b.PROJECT_ID,\n",
      "  b.SURVEY_NAME,\n",
      "  b.SURVEY_ID,\n",
      "  SDO_UTIL.TO_WKTGEOMETRY(b.GEOMETRY)AS WKT_GEOMETRY\n",
      "from\n",
      "  WHSE_WILDLIFE_INVENTORY.SPI_SURVEY_OBS_ALL_SP b\n",
      "  \n",
      "where b.species_code = 'M-OVCA'\n",
      "\n",
      "and \n",
      "\n",
      "SDO_ANYINTERACT (GEOMETRY,\n",
      "\tSDO_GEOMETRY(2003, 3005, NULL,\n",
      "\t\tSDO_ELEM_INFO_ARRAY(1,1003,3),\n",
      "\t\tSDO_ORDINATE_ARRAY(1493647.6,466354.8,1889017.9,862609.6) \n",
      "\t)\n",
      ") = 'TRUE'\n",
      "  \n",
      "\n",
      "2024-01-10 09:02:03,778 INFO sqlalchemy.engine.Engine [raw sql] {}\n",
      "2024-01-10 09:03:09,797 INFO sqlalchemy.engine.Engine \n",
      "select \n",
      "  b.SURVEY_OBSERVATION_ID as Observation_ID,\n",
      "  b.Species_Code,\n",
      "  b.ANIMAL_ID,\n",
      "  b.SEX,\n",
      "  b.OBSERVED_NUMBER,\n",
      "  b.OBSERVATION_DATETIME as Date_Time,\n",
      "  b.OBSERVATION_YEAR as Year,\n",
      "  b.OBSERVATION_MONTH as Month,\n",
      "  b.OBSERVATION_DAY as Day,\n",
      "  b.UTM_ZONE,\n",
      "  b.UTM_EASTING,\n",
      "  b.UTM_Northing,\n",
      "  b.PROJECT_NAME,\n",
      "  b.PROJECT_ID,\n",
      "  b.SURVEY_NAME,\n",
      "  b.SURVEY_ID,\n",
      "  SDO_UTIL.TO_WKTGEOMETRY(b.GEOMETRY)AS WKT_GEOMETRY\n",
      "from\n",
      "  WHSE_WILDLIFE_INVENTORY.SPI_TELEMETRY_OBS_ALL_SP b\n",
      "  \n",
      "where b.species_code = 'M-OVCA'\n",
      "\n",
      "and \n",
      "\n",
      "SDO_ANYINTERACT (GEOMETRY,\n",
      "\tSDO_GEOMETRY(2003, 3005, NULL,\n",
      "\t\tSDO_ELEM_INFO_ARRAY(1,1003,3),\n",
      "\t\tSDO_ORDINATE_ARRAY(1493647.6,466354.8,1889017.9,862609.6) \n",
      "\t)\n",
      ") = 'TRUE'\n",
      "  \n",
      "\n",
      "2024-01-10 09:03:09,799 INFO sqlalchemy.engine.Engine [raw sql] {}\n",
      "47742\n",
      "48709\n",
      "1205\n",
      "1577\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"def cat (m, d):\\n    if m <=3:\\n        return 'Winter'\\n    elif m == 12 and d >=15:\\n        return 'Winter'\\n    elif m == 11:\\n        return 'Movement'\\n    elif m == 12 and d <15:\\n        return 'Movement'\\n    elif m ==4 or m ==5:\\n        return 'Movement'\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#execute queries\n",
    "obvs_df=pandas.read_sql_query(sql_obvs, conn)\n",
    "tele_df=pandas.read_sql_query(sql_tele, conn)\n",
    "#Merge results into one table \n",
    "frames=[obvs_df,tele_df]\n",
    "result_df=pandas.concat(frames)\n",
    "\n",
    "#split data frame into two, pre and post 1998\n",
    "post_1998,pre_1998=[x for _, x in result_df.groupby(result_df['year']<=1998)]\n",
    "\n",
    "#split pre and post 1998 data frames into pre and post, winter and movment based on dates\n",
    "post_winter= post_1998.query('month <=3 or month =12' and 'day >=15')\n",
    "print(len(post_winter.index))\n",
    "\n",
    "post_movement=post_1998.query('month = 11 or month =12' and 'day <15 or month in (4,5)')\n",
    "print(len(post_movement.index))\n",
    "\n",
    "pre_winter= pre_1998.query('month <=3 or month =12' and 'day >=15')\n",
    "print(len(pre_winter.index))\n",
    "\n",
    "pre_movement= pre_1998.query('month = 11 or month =12' and 'day <15 or month in (4,5)')\n",
    "print(len(pre_movement.index))\n",
    "\n",
    "# OG function to define date ranges in data here for reference m=month, d=day\n",
    "\"\"\"def cat (m, d):\n",
    "    if m <=3:\n",
    "        return 'Winter'\n",
    "    elif m == 12 and d >=15:\n",
    "        return 'Winter'\n",
    "    elif m == 11:\n",
    "        return 'Movement'\n",
    "    elif m == 12 and d <15:\n",
    "        return 'Movement'\n",
    "    elif m ==4 or m ==5:\n",
    "        return 'Movement'\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post_1998_Winter_temp created\n",
      "Pre_1998_Winter_temp created\n",
      "Post_1998_Movement_temp created\n",
      "Pre_1998_Movement_temp created\n"
     ]
    }
   ],
   "source": [
    "#create temp gdb if it does not exist\n",
    "fgdb=os.path.join(\"T:\",\"BHS_Temp.gdb\")\n",
    "if not arcpy.Exists(fgdb):\n",
    "    arcpy.management.CreateFileGDB(\"T:\",\"BHS_Temp.gdb\")\n",
    "else: \n",
    "    print('gdb exists')\n",
    "\n",
    "arcpy.env.workspace=fgdb\n",
    "\n",
    "#names for temp lyrs \n",
    "tmp_lyrs=['Post_1998_Winter_temp','Pre_1998_Winter_temp','Post_1998_Movement_temp','Pre_1998_Movement_temp']\n",
    "dfs=[post_winter,pre_winter, post_movement, pre_movement]\n",
    "#create dictonary  of col name:type\n",
    "column_types = post_winter.dtypes.apply(lambda x: x.name).to_dict()\n",
    "\n",
    "#create temp fc if they do not exist and add cols to it \n",
    "for t,d in zip(tmp_lyrs,dfs):\n",
    "    if not arcpy.Exists(t):\n",
    "        arcpy.management.CreateFeatureclass(fgdb,\n",
    "            t,\n",
    "            'POINT',\n",
    "            spatial_reference=arcpy.SpatialReference(3005))\n",
    "        print(f'{t} created')\n",
    "    else: \n",
    "        print(f'{t} already exists')\n",
    "    #add cols from df to fc\n",
    "    for col in column_types:\n",
    "        if column_types[col] == 'int64' or column_types[col] == 'float64':\n",
    "            arcpy.management.AddField(t, col, 'DOUBLE')\n",
    "        elif column_types[col] == 'object':\n",
    "            arcpy.management.AddField(t, col, 'TEXT')\n",
    "        elif column_types[col] == 'datetime64[ns]':\n",
    "            arcpy.management.AddField(t, col, 'DATE')\n",
    "    #add points from df to fc        \n",
    "    with arcpy.da.InsertCursor(t, ['SHAPE@'] + list(d.columns)) as cursor:\n",
    "        for index, row in d.iterrows():\n",
    "            # Create a point geometry from WKT\n",
    "            point = arcpy.FromWKT(row['wkt_geometry'], arcpy.SpatialReference(3005))  # Update with the appropriate coordinate system code\n",
    "            row_nm=row.tolist()\n",
    "            values = [point] + row_nm\n",
    "            cursor.insertRow(values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#FCs\n",
    "e_post_winter=os.path.join(exsitng_gdb, 'Post_1998_Winter')\n",
    "e_post_movement=os.path.join(exsitng_gdb, 'Post_1998_Movement')\n",
    "e_pre_winter=os.path.join(exsitng_gdb, 'Pre_1998_Winter')\n",
    "e_pre_movement =os.path.join(exsitng_gdb, 'Pre_1998_Movement')\n",
    "\n",
    "t_post_winter=os.path.join(temp_gdb, 'Post_1998_Winter_temp')\n",
    "t_post_movement=os.path.join(temp_gdb, 'Post_1998_Movement_temp')\n",
    "t_pre_winter=os.path.join(temp_gdb, 'Pre_1998_Winter_temp')\n",
    "t_pre_movement =os.path.join(temp_gdb, 'Pre_1998_Movement_temp')\n",
    "\n",
    "fc_dict={e_post_winter:t_post_winter, e_post_movement:t_post_movement, e_pre_winter:t_pre_winter, e_pre_movement:t_pre_movement}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create or read xlsx\n",
    "if not os.path.exists(tracker):\n",
    "    wb= pyxl.Workbook()\n",
    "    ws=wb.active\n",
    "    ws1= wb.create_sheet('Data_Tracking',0)\n",
    "    header=['Date updated', 'feature class', 'Number of new features', 'Source', 'Updated by']\n",
    "    header_style=pyxl.styles.Font(size=12, bold=True)\n",
    "    ws1=wb['Data_Tracking']\n",
    "    ws1.append(header)\n",
    "    for cell in ws1[\"1:1\"]:\n",
    "        cell.font=header_style\n",
    "    wb.save(tracker)\n",
    "else:\n",
    "    wb= pyxl.load_workbook(tracker)\n",
    "    ws1=wb['Data_Tracking']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "select by layer\n",
      "0 features overlap, removing\n",
      "0 remaining, adding to master...\n",
      "no new feats\n"
     ]
    }
   ],
   "source": [
    "for key in fc_dict:\n",
    "    sel_feats=arcpy.management.SelectLayerByLocation(fc_dict[key], 'WITHIN', key)\n",
    "    print('select by layer')\n",
    "    del_feats=int(arcpy.management.GetCount(sel_feats).getOutput (0))\n",
    "    print(f'{del_feats} features overlap, removing')\n",
    "    arcpy.management.DeleteFeatures(fc_dict[key])\n",
    "    \n",
    "    feats=int(arcpy.management.GetCount(fc_dict[key]).getOutput (0))\n",
    "    print(f'{feats} remaining, adding to master...')\n",
    "    if feats>0:\n",
    "        field_mappings = arcpy.FieldMappings()\n",
    "        field_mappings.addTable(fc_dict[key])\n",
    "        field_mappings.addTable(key)\n",
    "        print('field mapping?')\n",
    "\n",
    "        arcpy.management.Append(fc_dict[key], key, schema_type=\"NO_TEST\", field_mapping=field_mappings)\n",
    "        print('append master class')\n",
    "        fc_name=key.split(r'\\\\')\n",
    "        fc_name=fc_name[-1]\n",
    "        # how do we get the source? flag from  \n",
    "        xlsx_append=[date.today, fc_name, feats, 'Comming soon', username]\n",
    "        print(xlsx_append)\n",
    "        ws1.append(xlsx_append)\n",
    "    elif feats == 0:\n",
    "        print( 'no new feats')\n",
    "\n",
    "    break\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
